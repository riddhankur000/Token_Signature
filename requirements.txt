# Core Deep Learning
torch>=2.4.0
torchvision
torchaudio

# Hugging Face Ecosystem (Crucial for Llama-3.2 & Phi-3.5)
# Note: Llama-3.2 requires transformers >= 4.45.0
transformers>=4.45.0
accelerate>=0.34.0
datasets>=3.0.0
huggingface-hub>=0.25.0

# Inference Engine (Used in extract_answer.py)
# Note: vllm is very specific about CUDA versions. 
# If this fails, remove it and see instructions below.
vllm>=0.6.0

# Math & Statistics (Used for Z-test and Spearman Correlation)
scipy>=1.10.0
numpy>=1.24.0
pandas

# Utilities (Used in various scripts)
tqdm
setproctitle
multiprocess
argparse